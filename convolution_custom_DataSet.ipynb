{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolution_custom_DataSet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4wJkizsdBnOHgjwAm0Uxu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhinoos-adibi/Deep-Learning-based-Computer_Vision/blob/main/convolution_custom_DataSet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COURSE: A deep understanding of deep learning\n",
        "\n",
        "SECTION: Convolution and transformations\n",
        "\n",
        "LECTURE: Creating and using custom DataSets\n",
        "\n",
        "TEACHER: Mike X Cohen, sincxpress.com\n",
        "\n",
        "COURSE URL: udemy.com/course/dudl/?couponCode=202108\n"
      ],
      "metadata": {
        "id": "bQWOpov2ZpF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI, review paper on data augmentation in DL:\n",
        "# https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0"
      ],
      "metadata": {
        "id": "Q-fbhPBtZq_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# import transformations and dataset/loader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats('svg')"
      ],
      "metadata": {
        "id": "qMtC34A1Zw3Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Import the data```\n",
        "\n"
      ],
      "metadata": {
        "id": "1A5YtbziZ0Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset (comes with colab!)\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# extract only the first 8\n",
        "labels = data[:8,0]\n",
        "data   = data[:8,1:]\n",
        "\n",
        "# normalize the data to a range of [0 1]\n",
        "dataNorm = data / np.max(data)\n",
        "\n",
        "# reshape to 2D!\n",
        "dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)\n",
        "\n",
        "# check sizes\n",
        "print(dataNorm.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# convert to torch tensor format\n",
        "dataT   = torch.tensor( dataNorm ).float()\n",
        "labelsT = torch.tensor( labels ).long()"
      ],
      "metadata": {
        "id": "1ISv8BoYZ4bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new class to create our custom\n",
        " dataset type"
      ],
      "metadata": {
        "id": "4REoaxGiZ8EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# My custom dataset class is modeled after the official class\n",
        "#??torch.utils.data.TensorDataset"
      ],
      "metadata": {
        "id": "5JirZChxaBSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customDataset(Dataset):\n",
        "  def __init__(self, tensors, transform=None):\n",
        "\n",
        "    # check that sizes of data and labels match\n",
        "    assert all(tensors[0].size(0)==t.size(0) for t in tensors), \"Size mismatch between tensors\"\n",
        "    \n",
        "    # assign inputs\n",
        "    self.tensors   = tensors\n",
        "    self.transform = transform\n",
        "\n",
        "  # what to do when someone wants and item from the dataset\n",
        "  def __getitem__(self, index): \n",
        "\n",
        "    # return transformed version of x if there are transforms\n",
        "    if self.transform:\n",
        "      x = self.transform(self.tensors[0][index])\n",
        "    else:\n",
        "      x = self.tensors[0][index]\n",
        "\n",
        "    # and return label\n",
        "    y = self.tensors[1][index]\n",
        "\n",
        "    return x,y # return the (data,label) tuple\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.tensors[0].size(0)"
      ],
      "metadata": {
        "id": "PJtWqDtcaDdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1wx6DBqUaIyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data -> dataset -> dataloader"
      ],
      "metadata": {
        "id": "NLG-4mcaaK9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: several transforms work only on PIL-format data, so it's common to transform\n",
        "#       to PIL, apply transformations, then transform back to tensor.\n",
        "\n",
        "# create a list of transforms to apply to the image\n",
        "imgtrans = T.Compose([ \n",
        "                      T.ToPILImage(),\n",
        "                      T.RandomVerticalFlip(p=.5),\n",
        "                      # T.RandomRotation(90), \n",
        "                      T.ToTensor()\n",
        "                       ])"
      ],
      "metadata": {
        "id": "3wclXavWaMEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now convert the data into datasets and then dataloaders\n",
        "\n",
        "# convert into PyTorch Datasets\n",
        "# NOTE: we have no test data here, but you should apply the same transformations to the test data\n",
        "train_data = customDataset((dataT,labelsT),imgtrans)\n",
        "\n",
        "# translate into dataloader objects\n",
        "dataLoaded = DataLoader(train_data,batch_size=8,shuffle=False)"
      ],
      "metadata": {
        "id": "mlWS2FiEaN-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "id": "e2x2-ya3aRXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Let's see the effects!```\n",
        "\n"
      ],
      "metadata": {
        "id": "7b-6QlzFaP5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import data from the dataloader, just like during training\n",
        "X,y = next(iter(dataLoaded))\n",
        "\n",
        "\n",
        "# create a figure\n",
        "fig,axs = plt.subplots(2,8,figsize=(16,4))\n",
        "\n",
        "\n",
        "# loop over images in the dataset\n",
        "for i in range(8):\n",
        "\n",
        "  # draw images\n",
        "  axs[0,i].imshow(dataT[i,0,:,:].detach(),cmap='gray')\n",
        "  axs[1,i].imshow(X[i,0,:,:].detach(),cmap='gray')\n",
        "\n",
        "  # some niceties\n",
        "  for row in range(2):\n",
        "    axs[row,i].set_xticks([])\n",
        "    axs[row,i].set_yticks([])\n",
        "\n",
        "# row labels\n",
        "axs[0,0].set_ylabel('Original')\n",
        "axs[1,0].set_ylabel('torch dataset')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9zIJi0mnaWcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important to know: we haven't actually increased the amount of data\n",
        "len(train_data)"
      ],
      "metadata": {
        "id": "mfSyYNQJaZVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}